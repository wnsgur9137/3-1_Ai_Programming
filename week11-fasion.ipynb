{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 2s 804us/step - loss: 0.5446 - accuracy: 0.8138\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 1s 797us/step - loss: 0.4119 - accuracy: 0.8546\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 2s 805us/step - loss: 0.3770 - accuracy: 0.8661\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 2s 801us/step - loss: 0.3580 - accuracy: 0.8709\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 2s 808us/step - loss: 0.3429 - accuracy: 0.8777\n",
      "313/313 [==============================] - 0s 652us/step - loss: 0.3941 - accuracy: 0.8616\n",
      "모델1의 정확도: 0.8615999817848206\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_2 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 32)                25120     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,450\n",
      "Trainable params: 25,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1050번째 이미지 예측 결과\n",
      "[0.   0.   0.03 0.   0.9  0.   0.07 0.   0.   0.  ]\n",
      "615번째 이미지 예측 결과\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.5422 - accuracy: 0.8117\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3953 - accuracy: 0.8583\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3575 - accuracy: 0.8711\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3340 - accuracy: 0.8784\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3167 - accuracy: 0.8846\n",
      "313/313 [==============================] - 0s 712us/step - loss: 0.3596 - accuracy: 0.8694\n",
      "모델2의 정확도: 0.8694000244140625\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_3 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 64)                50240     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 16)                272       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 51,552\n",
      "Trainable params: 51,552\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1050번째 이미지 예측 결과\n",
      "[0.   0.   0.13 0.   0.72 0.   0.1  0.   0.04 0.   0.   0.   0.   0.\n",
      " 0.   0.  ]\n",
      "615번째 이미지 예측 결과\n",
      "[0.   0.   0.   0.   0.   0.   0.   0.99 0.   0.01 0.   0.   0.   0.\n",
      " 0.   0.  ]\n",
      "-----------\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import datasets, layers, models\n",
    "\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "plt.imshow(train_images[0])\n",
    "\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "\n",
    "# 모델 1\n",
    "model = models.Sequential()\n",
    "model.add(layers.Flatten(input_shape=(28, 28)))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=5)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print('모델1의 정확도:', test_acc)\n",
    "model.summary()\n",
    "\n",
    "# 모델 1 1050번째 test이미지 카테고리 예측 결과\n",
    "print('1050번째 이미지 예측 결과')\n",
    "test_pred=model.predict(test_images)\n",
    "plt.imshow(test_images[1050])\n",
    "print(np.round(test_pred[1050],2))\n",
    "\n",
    "# 모델 1 615번째 test이미지 카테고리 예측 결과\n",
    "print('615번째 이미지 예측 결과')\n",
    "test_pred=model.predict(test_images)\n",
    "plt.imshow(test_images[615])\n",
    "print(np.round(test_pred[615],2))\n",
    "\n",
    "\n",
    "\n",
    "print('\\n', '-'*20, sep='')\n",
    "print('-'*20)\n",
    "print('-'*20, '\\n', sep='')\n",
    "\n",
    "\n",
    "\n",
    "# 모델 2\n",
    "model2 = models.Sequential()\n",
    "model2.add(layers.Flatten(input_shape=(28, 28)))\n",
    "model2.add(layers.Dense(64, activation='relu'))\n",
    "model2.add(layers.Dense(16, activation='relu'))\n",
    "model2.add(layers.Dense(16, activation='softmax'))\n",
    "\n",
    "model2.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model2.fit(train_images, train_labels, epochs=5)\n",
    "\n",
    "test_loss, test_acc = model2.evaluate(test_images, test_labels)\n",
    "print('모델2의 정확도:', test_acc)\n",
    "model2.summary()\n",
    "\n",
    "# 모델 1 1050번째 test이미지 카테고리 예측 결과\n",
    "print('1050번째 이미지 예측 결과')\n",
    "test_pred=model2.predict(test_images)\n",
    "plt.imshow(test_images[1050])\n",
    "print(np.round(test_pred[1050],2))\n",
    "\n",
    "# 모델 1 615번째 test이미지 카테고리 예측 결과\n",
    "print('615번째 이미지 예측 결과')\n",
    "test_pred=model2.predict(test_images)\n",
    "plt.imshow(test_images[615])\n",
    "print(np.round(test_pred[615],2))\n",
    "print('-----------')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0d151449e4628feead7016338a20eeec6b2249142759a5d6c87ab1fe3bbdc8d5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
